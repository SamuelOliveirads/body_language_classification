# body_language_classification

## Overview

The aim of this project is to develop a system capable of classifying different actions carried out by people, using as input images or videos, which can be captured live via a webcam or provided as pre-recorded files.

## How to install dependencies

Declare any dependencies in `src/requirements.txt` for `pip` installation.

To install them, run:

```
pip install -r src/requirements.txt
```

### Dataset

The data used is provided by the MPII and although it does not have typically common actions, it will serve the purpose of the project.
   - Link: [MPII Human Pose Dataset](http://human-pose.mpi-inf.mpg.de/)

> Note: If you don't want to download it, I'll leave the filtered bases in the intermediate folders

## How to run on a notebook

You can run the latest notebook v.2.0-detect-webcam-input.ipynb to view the final project, the other notebooks are earlier versions.
